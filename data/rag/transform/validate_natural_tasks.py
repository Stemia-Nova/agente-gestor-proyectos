#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
validate_natural_tasks.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Valida la calidad de las tareas naturalizadas antes de indexarlas en ChromaDB.

Eval√∫a si los textos generados por FLAN-T5 contienen informaci√≥n clave:
- Estado
- Prioridad
- Asignado o responsable

üìä Genera un informe con m√©tricas de completitud y ejemplos de errores.
"""

import json
from pathlib import Path
from collections import Counter
from tqdm import tqdm

# ============================
# Configuraci√≥n
# ============================
INPUT_PATH = Path("data/processed/task_natural_mt5.jsonl")
REQUIRED_KEYWORDS = ["estado", "prioridad", "asignad", "sprint"]
MIN_LENGTH = 40  # longitud m√≠nima del texto natural

# ============================
# Funciones principales
# ============================
def read_jsonl(path: Path):
    """Lee un archivo JSONL y devuelve una lista de dicts."""
    with path.open("r", encoding="utf-8") as f:
        return [json.loads(line) for line in f if line.strip()]


def validate_text(text: str) -> dict:
    """Eval√∫a un texto y devuelve un dict con flags de presencia de keywords."""
    text_lower = text.lower()
    flags = {kw: (kw in text_lower) for kw in REQUIRED_KEYWORDS}
    flags["longitud_ok"] = len(text.strip()) >= MIN_LENGTH
    return flags


def evaluate_dataset(records: list) -> dict:
    """Eval√∫a el dataset completo y devuelve estad√≠sticas agregadas."""
    totals = Counter()
    failures = []

    for r in tqdm(records, desc="Evaluando tareas"):
        text = r.get("text", "")
        flags = validate_text(text)

        if all(flags.values()):
            totals["completas"] += 1
        else:
            totals["incompletas"] += 1
            failures.append({"text": text, "flags": flags, "meta": r.get("metadata", {})})

    total = len(records)
    score = totals["completas"] / total * 100 if total else 0
    return {"total": total, "score": score, "totals": totals, "failures": failures[:5]}


# ============================
# Main
# ============================
def main():
    if not INPUT_PATH.exists():
        raise FileNotFoundError(f"No existe el archivo: {INPUT_PATH}")

    data = read_jsonl(INPUT_PATH)
    print(f"üìÇ Analizando {len(data)} tareas naturalizadas desde {INPUT_PATH}")

    results = evaluate_dataset(data)

    print("\nüìä RESULTADOS DE VALIDACI√ìN")
    print(f"Total de tareas: {results['total']}")
    print(f"Tareas completas: {results['totals']['completas']} ‚úÖ")
    print(f"Tareas incompletas: {results['totals']['incompletas']} ‚ö†Ô∏è")
    print(f"Porcentaje de completitud: {results['score']:.1f}%\n")

    if results["failures"]:
        print("üß© Ejemplos de tareas incompletas:")
        for f in results["failures"]:
            meta = f.get("meta", {})
            print(f"\n--- {meta.get('sprint', '-')}, {meta.get('task_id', '-')}")
            print("Texto:", f["text"][:200].replace("\n", " "))
            print("Flags:", f["flags"])


if __name__ == "__main__":
    main()
