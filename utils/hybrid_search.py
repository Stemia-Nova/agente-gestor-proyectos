#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HybridSearch â€” versiÃ³n optimizada y tipada para base Ãºnica (clickup_tasks)
---------------------------------------------------------------------------
Motor de bÃºsqueda hÃ­brido sobre la base Chroma del Agente Gestor de Proyectos.

âœ” Compatible con Chroma â‰¥0.5.x
âœ” IntegraciÃ³n directa con la colecciÃ³n 'clickup_tasks'
âœ” Combina bÃºsqueda semÃ¡ntica (MiniLM) + reranker CrossEncoder
âœ” Manejo seguro de tipos y datos opcionales
"""

from __future__ import annotations
import json
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, cast
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import chromadb

# =============================================================
# ðŸ“‚ ConfiguraciÃ³n general
# =============================================================
CHROMA_PATH = Path("data/rag/chroma_db")
DEFAULT_MODEL = "sentence-transformers/all-MiniLM-L12-v2"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


class HybridSearch:
    """BÃºsqueda hÃ­brida (semÃ¡ntica + reranker) sobre colecciÃ³n Ãºnica de Chroma."""

    def __init__(self, db_path: str | Path = CHROMA_PATH) -> None:
        self.db_path = str(db_path)
        self.chroma = chromadb.PersistentClient(path=self.db_path)
        self.embedder = SentenceTransformer(DEFAULT_MODEL, device=DEVICE)
        self.collection_name = "clickup_tasks"

        try:
            self.collection = self.chroma.get_collection(self.collection_name)
        except Exception:
            raise RuntimeError(f"âŒ No se encontrÃ³ la colecciÃ³n '{self.collection_name}' en {db_path}")

        print(f"âœ… HybridSearch inicializado sobre colecciÃ³n '{self.collection_name}'.")

        # Reranker CrossEncoder (reordenamiento semÃ¡ntico fino)
        self.reranker_tokenizer = AutoTokenizer.from_pretrained("cross-encoder/ms-marco-MiniLM-L-6-v2")
        self.reranker_model = AutoModelForSequenceClassification.from_pretrained(
            "cross-encoder/ms-marco-MiniLM-L-6-v2"
        ).to(DEVICE)

    # =============================================================
    # ðŸ“¥ Recolectar documentos
    # =============================================================
    def _collect_documents(self) -> Tuple[List[str], List[Dict[str, Any]]]:
        """Obtiene todos los documentos y metadatos de la colecciÃ³n Chroma."""
        docs: List[str] = []
        metas: List[Dict[str, Any]] = []

        try:
            data = self.collection.get(include=cast(Any, ["documents", "metadatas"])) or {}
            raw_docs = data.get("documents") or []
            raw_metas = data.get("metadatas") or []

            # Garantizar tipos vÃ¡lidos
            docs = list(raw_docs) if isinstance(raw_docs, list) else []
            metas = [dict(m) for m in raw_metas if isinstance(m, dict)]
        except Exception as e:
            print(f"âš ï¸ Error al recolectar documentos: {e}")

        return docs, metas

    # =============================================================
    # ðŸ” Reranking
    # =============================================================
    def _rerank(self, query: str, docs: List[str]) -> List[Tuple[str, float]]:
        """Reordena los documentos segÃºn similitud contextual con CrossEncoder."""
        if not docs:
            return []

        pairs = [(query, d) for d in docs]
        inputs = self.reranker_tokenizer(
            pairs,
            padding=True,
            truncation=True,
            return_tensors="pt",
            max_length=256,
        ).to(DEVICE)

        with torch.no_grad():
            scores = self.reranker_model(**inputs).logits.squeeze().cpu().numpy()

        if isinstance(scores, float):
            scores = np.array([scores])
        sorted_idx = np.argsort(scores)[::-1]
        return [(docs[i], float(scores[i])) for i in sorted_idx]

    # =============================================================
    # ðŸ” Consulta semÃ¡ntica principal
    # =============================================================
    def query(self, text: str, k: int = 5) -> List[Dict[str, Any]]:
        """Ejecuta bÃºsqueda semÃ¡ntica + reranking sobre la colecciÃ³n."""
        query_emb = self.embedder.encode([text], convert_to_numpy=True)
        results: List[Dict[str, Any]] = []

        try:
            q = self.collection.query(
                query_embeddings=query_emb,
                n_results=k,
                include=cast(Any, ["documents", "metadatas"]),
            ) or {}

            raw_docs = (q.get("documents") or [[]])[0] or []
            raw_metas = (q.get("metadatas") or [[]])[0] or []

            # Validar estructura
            docs = list(raw_docs) if isinstance(raw_docs, list) else []
            metas = [dict(m) for m in raw_metas if isinstance(m, dict)]

            results.extend({"text": d, "metadata": m} for d, m in zip(docs, metas))
        except Exception as e:
            print(f"âš ï¸ Error en query: {e}")

        if not results:
            return []

        reranked = self._rerank(text, [r["text"] for r in results])
        top_docs = {r[0] for r in reranked[:k]}
        return [r for r in results if r["text"] in top_docs]

    # =============================================================
    # ðŸ“Š Agregaciones globales
    # =============================================================
    def aggregate_counts(self) -> Dict[str, Any]:
        """Devuelve un resumen de estados de tareas."""
        docs, metas = self._collect_documents()
        agg = {"total": len(docs), "done": 0, "in_progress": 0, "todo": 0, "blocked": 0}

        for m in metas:
            st = str(m.get("status", "")).lower()
            if "finaliz" in st or "done" in st or "complet" in st:
                agg["done"] += 1
            elif "curso" in st or "progress" in st:
                agg["in_progress"] += 1
            elif "pend" in st or "todo" in st:
                agg["todo"] += 1
            if m.get("is_blocked"):
                agg["blocked"] += 1

        return agg

    # =============================================================
    # ðŸš« Listar tareas bloqueadas
    # =============================================================
    def list_blocked(self) -> List[Dict[str, Any]]:
        """Devuelve todas las tareas marcadas como bloqueadas."""
        docs, metas = self._collect_documents()
        blocked = []
        for d, m in zip(docs, metas):
            if m.get("is_blocked"):
                blocked.append({"text": d, "metadata": m})
        return blocked


# =============================================================
# ðŸ§ª Ejemplo de uso directo
# =============================================================
if __name__ == "__main__":
    hs = HybridSearch()
    print("\nðŸ”Ž Consulta de ejemplo:")
    query = "tareas pendientes del sprint 3"
    results = hs.query(query)
    for r in results:
        print("-", r["metadata"].get("name"), "â†’", r["metadata"].get("status"))
