#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸ§ª TEST DIRECTO DE CONTEOS - Sin OpenAI
========================================
Prueba directamente la funciÃ³n _handle_count_question
que no requiere OpenAI y funciona solo con ChromaDB.
"""

import sys
sys.path.insert(0, '/home/st12/agente-gestor-proyectos/agente-gestor-proyectos')

from utils.hybrid_search import HybridSearch

# Colores para output
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
BLUE = "\033[94m"
RESET = "\033[0m"

def print_test(num, query, expected):
    print(f"\n{BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}")
    print(f"{BLUE}ðŸ§ª TEST {num}: {query}{RESET}")
    print(f"{BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}")
    return expected

def check_result(expected, actual, test_name):
    if actual and str(expected) in actual:
        print(f"{GREEN}âœ… PASS{RESET} - {test_name}")
        print(f"   Respuesta: {actual}")
        return True
    else:
        print(f"{RED}âŒ FAIL{RESET} - {test_name}")
        print(f"   Esperado: contiene '{expected}'")
        print(f"   Obtenido: {actual}")
        return False

def main():
    print(f"\n{YELLOW}{'=' * 80}{RESET}")
    print(f"{YELLOW}ðŸš€ TEST DIRECTO DE CONTEOS (Sin OpenAI){RESET}")
    print(f"{YELLOW}{'=' * 80}{RESET}\n")
    
    # Inicializar HybridSearch
    print("ðŸ”§ Inicializando HybridSearch...")
    searcher = HybridSearch(db_path="data/rag/chroma_db")
    print("âœ… HybridSearch inicializado correctamente\n")
    
    results = []
    
    # TESTS CRÃTICOS DE CONTEO
    tests = [
        ("Â¿cuÃ¡ntas tareas hay en total?", "24"),
        ("Â¿cuÃ¡ntas tareas hay en el sprint 3?", "8"),
        ("Â¿cuÃ¡ntas tareas completadas hay en el sprint 3?", "1"),  # EL MÃS CRÃTICO
        ("Â¿cuÃ¡ntas tareas pendientes hay en el sprint 3?", "4"),
        ("Â¿cuÃ¡ntas tareas tiene Jorge?", "7"),
        ("Â¿cuÃ¡ntas tareas tiene Jorge en el sprint 3?", "5"),
        ("Â¿cuÃ¡ntas tareas tiene Laura?", "17"),
        ("Â¿hay tareas bloqueadas?", "bloqueada"),
        ("Â¿hay tareas con comentarios?", "1"),  # Solo activas
        ("Â¿hay tareas con subtareas?", "3"),
        ("Â¿hay tareas con dudas?", "no hay"),  # No existen dudas
        ("Â¿hay tareas con la etiqueta data?", "4"),
        ("Â¿hay tareas con la etiqueta bloqueada?", "3"),
    ]
    
    for i, (query, expected) in enumerate(tests, 1):
        expected_val = print_test(i, query, expected)
        
        # Llamar directamente a _handle_count_question
        response = searcher._handle_count_question(query)
        
        if response:
            results.append(check_result(expected_val, response, f"Test {i}"))
        else:
            print(f"{YELLOW}âš ï¸  SKIP{RESET} - La funciÃ³n retornÃ³ None (delegarÃ­a al LLM)")
            print(f"   Query: {query}")
            results.append(False)
    
    # RESUMEN
    print(f"\n{YELLOW}{'=' * 80}{RESET}")
    print(f"{YELLOW}ðŸ“Š RESUMEN DE RESULTADOS{RESET}")
    print(f"{YELLOW}{'=' * 80}{RESET}\n")
    
    passed = sum(results)
    total = len(results)
    percentage = (passed / total) * 100 if total > 0 else 0
    
    print(f"Tests ejecutados: {total}")
    print(f"Tests pasados: {GREEN}{passed}{RESET}")
    print(f"Tests fallidos: {RED}{total - passed}{RESET}")
    print(f"Porcentaje de Ã©xito: {GREEN if percentage >= 80 else RED}{percentage:.1f}%{RESET}\n")
    
    if percentage == 100:
        print(f"{GREEN}ðŸŽ‰ Â¡TODOS LOS TESTS PASARON!{RESET}")
    elif percentage >= 80:
        print(f"{YELLOW}âš ï¸  Algunos tests fallaron.{RESET}")
    else:
        print(f"{RED}âŒ Muchos tests fallaron.{RESET}")
    
    print(f"\n{YELLOW}{'=' * 80}{RESET}\n")
    
    return percentage >= 80

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
