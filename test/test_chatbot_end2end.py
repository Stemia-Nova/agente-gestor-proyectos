#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Prueba End-to-End del Agente Gestor de Proyectos con LLM real (OpenAI).
Reproduce la misma ruta que Chainlit:
HybridSearch â†’ contexto â†’ _build_prompt â†’ _synthesize_sync_openai
"""

import asyncio
from chatbot import handlers


async def simulate_chat(message: str):
    """Simula un turno de chat completo como si se hiciera desde Chainlit."""
    hs = handlers._ensure_hs()

    print(f"\nğŸ§  Consulta del usuario: {message}")

    # 1ï¸âƒ£ Ejecutar bÃºsqueda hÃ­brida (igual que en handlers.on_message)
    try:
        results = await asyncio.get_running_loop().run_in_executor(None, hs.query, message)
    except Exception as e:
        print(f"âŒ Error en HybridSearch: {e}")
        return

    if not results:
        print("âš ï¸ No se encontraron resultados relevantes.")
        return

    # 2ï¸âƒ£ Construir contexto textual
    context_text = handlers._format_results(results)
    prompt = handlers._build_prompt(context_text, message)

    # 3ï¸âƒ£ Generar respuesta real con OpenAI (usa tu OPENAI_API_KEY)
    try:
        synthesized = await asyncio.get_running_loop().run_in_executor(
            None, handlers._synthesize_sync_openai, context_text, message
        )
        print(f"\nğŸ§© PROMPT:\n{prompt[:600]}...\n")
        print(f"ğŸ’¬ RESPUESTA:\n{synthesized}\n")
    except Exception as e:
        print(f"âŒ Error al generar respuesta con OpenAI: {e}")


def test_end_to_end_openai():
    """Ejecuta varias preguntas clave usando el pipeline real."""
    queries = [
        "Â¿CuÃ¡ntos sprints hay?",
        "Â¿CuÃ¡ntas tareas completadas hay en total?",
        "Â¿QuÃ© tareas tiene Laura?",
        "Â¿QuÃ© tareas estÃ¡n bloqueadas?",
        "Â¿QuÃ© tareas tiene Jorge Aguadero?",
        "Â¿QuÃ© sprint estÃ¡ activo ahora?"
    ]

    loop = asyncio.get_event_loop()
    for q in queries:
        loop.run_until_complete(simulate_chat(q))
