#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
BaterÃ­a de pruebas funcionales para el Agente Gestor de Proyectos.

âœ… Objetivos:
 - Validar bÃºsquedas hÃ­bridas y conteos coherentes.
 - Confirmar que las consultas comunes (estado, sprints, bloqueos)
   se responden correctamente usando HybridSearch + Reranker.
 - Asegurar que los filtros y el registro de sprints funcionan.

Ejecutar con:
    pytest -v test/test_agent_behavior.py
"""

import json
from pathlib import Path
from utils.hybrid_search import HybridSearch


# ================================================================
# CONFIGURACIÃ“N
# ================================================================

CHROMA_PATH = Path("data/rag/chroma_db")
RESULTS_DIR = Path("data/debug")
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# ================================================================
# ESCENARIOS DE PRUEBA
# ================================================================

TEST_QUERIES = [
    # ðŸ”¹ Estado de tareas
    ("Â¿QuÃ© tareas estÃ¡n bloqueadas?", ["bloqueada", "blocked"]),
    ("Â¿Hay alguna tarea con impedimentos?", ["bloqueada", "blocked"]),
    ("Â¿QuÃ© tareas estÃ¡n en progreso?", ["in_progress", "progreso"]),
    ("Â¿CuÃ¡les estÃ¡n finalizadas?", ["done", "finalizada", "cerrada"]),
    ("Â¿Hay tareas sin empezar?", ["to_do", "pendiente", "por hacer"]),
    ("Â¿QuÃ© tareas estÃ¡n pendientes de revisiÃ³n?", ["review", "revisiÃ³n"]),

    # ðŸ”¹ PriorizaciÃ³n y urgencia
    ("Â¿QuÃ© tareas son urgentes?", ["urgent", "urgente"]),

    # ðŸ”¹ Sprints
    ("Â¿CuÃ¡ntas tareas hay en el Sprint 1?", ["Sprint 1"]),
    ("MuÃ©strame las tareas del Sprint 2", ["Sprint 2"]),
    ("Â¿QuÃ© hay en el Sprint actual?", ["Sprint 3"]),
    ("Â¿QuÃ© tareas tiene el Sprint 3?", ["Sprint 3"]),

    # ðŸ”¹ Conteo y responsables
    ("Â¿QuÃ© tareas estÃ¡n completadas o cerradas?", ["done", "finalizada"]),
    ("Â¿CuÃ¡ntas tareas tenemos en total?", ["tarea", "task"]),
    ("Â¿QuÃ© tareas tiene Jorge Aguadero?", ["Jorge", "Aguadero"]),
    ("Â¿QuÃ© tareas tiene Laura PÃ©rez?", ["Laura", "PÃ©rez"]),
]


# ================================================================
# TEST PRINCIPAL
# ================================================================

def test_hybrid_behavior():
    print("\n==============================")
    print("ðŸ” BATERÃA DE PRUEBAS DEL AGENTE GESTOR DE PROYECTOS")
    print("==============================\n")

    hs = HybridSearch(chroma_base=CHROMA_PATH)
    coherent_count = 0

    for query, expected_keywords in TEST_QUERIES:
        print(f"\nðŸ§  Consulta: {query}")
        try:
            results = hs.query(query, k=5, scope="all")
            if not results:
                print("âŒ Sin resultados.\n")
                continue

            # Guardar resultados para inspecciÃ³n manual
            with open(RESULTS_DIR / "last_results.json", "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            # Evaluar coherencia: si contiene palabras esperadas
            joined_texts = " ".join([r["text"].lower() for r in results])
            hits = sum(1 for kw in expected_keywords if kw.lower() in joined_texts)

            if hits > 0:
                coherent_count += 1
                print(f"âœ… Resultado coherente: contiene {hits}/{len(expected_keywords)} keywords esperadas {expected_keywords}")
            else:
                print(f"âŒ No se encontraron coincidencias esperadas: {expected_keywords}")
                print("   Ejemplo de resultados obtenidos:")
                for r in results[:2]:
                    meta = r.get("metadata", {})
                    print(f" - {meta.get('task_id', '-')}: {meta.get('status', '?')} ({meta.get('sprint', '-')}) â€” {r.get('text', '')[:80]}...")

        except Exception as e:
            print(f"âŒ Error durante la bÃºsqueda: {e}")

    total = len(TEST_QUERIES)
    print("\n==============================")
    print("ðŸ“Š RESULTADO FINAL DE PRUEBAS")
    print("==============================")
    print(f"âœ… {coherent_count}/{total} consultas coherentes ({coherent_count/total*100:.1f}%)\n")

    assert coherent_count >= total * 0.8, "Menos del 80% de consultas coherentes â€” revisar embeddings o pipeline."
